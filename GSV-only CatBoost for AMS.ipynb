{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7429f881-7463-457d-ad51-d2ca71152a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import catboost\n",
    "from catboost import datasets\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from bayes_opt import BayesianOptimization\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import *\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error  # Ensure this import is included\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cabef1c-260e-49fc-b03b-4aa1bcb63b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figures' format\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4c90fa3-a8a8-40c7-a721-663eda6a210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.3\n",
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "# CatBoost check-up\n",
    "print(catboost.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc2921fe-1936-4e64-bafb-d90e56733e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input files\n",
    "ams,preds = pd.read_csv('ams_gsv.csv'), pd.read_csv('ams_gsv_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22f03d51-d86a-41af-863f-9cd96b334a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting 'income' and 'id' columns\n",
    "income = ams['income']\n",
    "id = preds['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0488916-fc9c-45ee-9505-95a490335ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising predictor variables\n",
    "first_col = ams.iloc[:, 0]\n",
    "remaining_cols = ams.iloc[:, 1:]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the remaining columns of X and transform them\n",
    "remaining_scaled = pd.DataFrame(scaler.fit_transform(remaining_cols), columns=remaining_cols.columns)\n",
    "\n",
    "# Reset indices to ensure they align for concatenation\n",
    "first_col = first_col.reset_index(drop=True)\n",
    "remaining_scaled = remaining_scaled.reset_index(drop=True)\n",
    "\n",
    "# Concatenate the first column back with the scaled remaining columns\n",
    "ams = pd.concat([first_col, remaining_scaled], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85c04b26-60f9-4f04-9063-8eeab5036e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising predictor variables\n",
    "first_col = preds.iloc[:, 0]\n",
    "remaining_cols = preds.iloc[:, 1:]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the remaining columns of X and transform them\n",
    "remaining_scaled = pd.DataFrame(scaler.fit_transform(remaining_cols), columns=remaining_cols.columns)\n",
    "\n",
    "# Reset indices to ensure they align for concatenation\n",
    "first_col = first_col.reset_index(drop=True)\n",
    "remaining_scaled = remaining_scaled.reset_index(drop=True)\n",
    "\n",
    "# Concatenate the first column back with the scaled remaining columns\n",
    "preds = pd.concat([first_col, remaining_scaled], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e720bed-65cb-43e9-8305-8d33da03f9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>gsv_apartments</th>\n",
       "      <th>gsv_commercial</th>\n",
       "      <th>gsv_greenery</th>\n",
       "      <th>gsv_historical</th>\n",
       "      <th>gsv_impervious</th>\n",
       "      <th>gsv_industrial</th>\n",
       "      <th>gsv_other</th>\n",
       "      <th>gsv_private</th>\n",
       "      <th>gsv_water</th>\n",
       "      <th>...</th>\n",
       "      <th>gsv_colour_saturation_std</th>\n",
       "      <th>gsv_colour_brightness_mean</th>\n",
       "      <th>gsv_colour_brightness_std</th>\n",
       "      <th>gsv_disorderliness_mean</th>\n",
       "      <th>gsv_disorderliness_std</th>\n",
       "      <th>gsv_std_mean</th>\n",
       "      <th>gsv_std_std</th>\n",
       "      <th>gsv_contrast_mean</th>\n",
       "      <th>gsv_contrast_std</th>\n",
       "      <th>gsv_coherence_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00-20 low</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172227</td>\n",
       "      <td>0.492173</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>0.862601</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.379061</td>\n",
       "      <td>0.195787</td>\n",
       "      <td>0.205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-20 low</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172227</td>\n",
       "      <td>0.492173</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>0.862601</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.379061</td>\n",
       "      <td>0.195787</td>\n",
       "      <td>0.205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00-20 low</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>0.318617</td>\n",
       "      <td>0.839201</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.681289</td>\n",
       "      <td>0.258832</td>\n",
       "      <td>0.318707</td>\n",
       "      <td>0.243122</td>\n",
       "      <td>0.278741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00-20 low</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162134</td>\n",
       "      <td>0.519754</td>\n",
       "      <td>0.516824</td>\n",
       "      <td>0.899050</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>0.485765</td>\n",
       "      <td>0.234291</td>\n",
       "      <td>0.042244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00-20 low</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172227</td>\n",
       "      <td>0.492173</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>0.862601</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.379061</td>\n",
       "      <td>0.195787</td>\n",
       "      <td>0.205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>80-100 high</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152469</td>\n",
       "      <td>0.901167</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.642786</td>\n",
       "      <td>0.446232</td>\n",
       "      <td>0.571405</td>\n",
       "      <td>0.165541</td>\n",
       "      <td>0.119023</td>\n",
       "      <td>0.138799</td>\n",
       "      <td>0.121806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>80-100 high</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125397</td>\n",
       "      <td>0.721157</td>\n",
       "      <td>0.323803</td>\n",
       "      <td>0.897157</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.796267</td>\n",
       "      <td>0.229601</td>\n",
       "      <td>0.421859</td>\n",
       "      <td>0.242305</td>\n",
       "      <td>0.154616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>80-100 high</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393437</td>\n",
       "      <td>0.446629</td>\n",
       "      <td>0.077663</td>\n",
       "      <td>0.909020</td>\n",
       "      <td>0.163496</td>\n",
       "      <td>0.735336</td>\n",
       "      <td>0.118362</td>\n",
       "      <td>0.311484</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>0.094039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>80-100 high</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172227</td>\n",
       "      <td>0.492173</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>0.862601</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.379061</td>\n",
       "      <td>0.195787</td>\n",
       "      <td>0.205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>80-100 high</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172227</td>\n",
       "      <td>0.492173</td>\n",
       "      <td>0.268796</td>\n",
       "      <td>0.862601</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>0.273291</td>\n",
       "      <td>0.379061</td>\n",
       "      <td>0.195787</td>\n",
       "      <td>0.205824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4275 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           income  gsv_apartments  gsv_commercial  gsv_greenery  \\\n",
       "0       00-20 low        0.000000            0.00      0.000000   \n",
       "1       00-20 low        0.000000            0.00      0.000000   \n",
       "2       00-20 low        0.142857            0.25      0.000000   \n",
       "3       00-20 low        0.142857            0.50      0.000000   \n",
       "4       00-20 low        0.000000            0.00      0.000000   \n",
       "...           ...             ...             ...           ...   \n",
       "4270  80-100 high        0.000000            0.00      0.333333   \n",
       "4271  80-100 high        0.142857            0.00      0.000000   \n",
       "4272  80-100 high        0.000000            0.00      0.000000   \n",
       "4273  80-100 high        0.000000            0.00      0.000000   \n",
       "4274  80-100 high        0.000000            0.00      0.000000   \n",
       "\n",
       "      gsv_historical  gsv_impervious  gsv_industrial  gsv_other  gsv_private  \\\n",
       "0                0.0            0.00             0.0       0.00     0.000000   \n",
       "1                0.0            0.00             0.0       0.00     0.000000   \n",
       "2                0.0            0.00             0.0       0.00     0.000000   \n",
       "3                0.0            0.00             0.0       0.00     0.000000   \n",
       "4                0.0            0.00             0.0       0.00     0.000000   \n",
       "...              ...             ...             ...        ...          ...   \n",
       "4270             0.0            0.25             0.0       0.00     0.000000   \n",
       "4271             0.0            0.00             0.0       0.00     0.166667   \n",
       "4272             0.0            0.00             0.0       0.25     0.000000   \n",
       "4273             0.0            0.00             0.0       0.00     0.000000   \n",
       "4274             0.0            0.00             0.0       0.00     0.000000   \n",
       "\n",
       "      gsv_water  ...  gsv_colour_saturation_std  gsv_colour_brightness_mean  \\\n",
       "0      0.000000  ...                   0.172227                    0.492173   \n",
       "1      0.000000  ...                   0.172227                    0.492173   \n",
       "2      0.000000  ...                   0.066005                    0.633977   \n",
       "3      0.000000  ...                   0.162134                    0.519754   \n",
       "4      0.000000  ...                   0.172227                    0.492173   \n",
       "...         ...  ...                        ...                         ...   \n",
       "4270   0.000000  ...                   0.152469                    0.901167   \n",
       "4271   0.000000  ...                   0.125397                    0.721157   \n",
       "4272   0.333333  ...                   0.393437                    0.446629   \n",
       "4273   0.000000  ...                   0.172227                    0.492173   \n",
       "4274   0.000000  ...                   0.172227                    0.492173   \n",
       "\n",
       "      gsv_colour_brightness_std  gsv_disorderliness_mean  \\\n",
       "0                      0.268796                 0.862601   \n",
       "1                      0.268796                 0.862601   \n",
       "2                      0.318617                 0.839201   \n",
       "3                      0.516824                 0.899050   \n",
       "4                      0.268796                 0.862601   \n",
       "...                         ...                      ...   \n",
       "4270                   0.239116                 0.642786   \n",
       "4271                   0.323803                 0.897157   \n",
       "4272                   0.077663                 0.909020   \n",
       "4273                   0.268796                 0.862601   \n",
       "4274                   0.268796                 0.862601   \n",
       "\n",
       "      gsv_disorderliness_std  gsv_std_mean  gsv_std_std  gsv_contrast_mean  \\\n",
       "0                   0.155033      0.652722     0.273291           0.379061   \n",
       "1                   0.155033      0.652722     0.273291           0.379061   \n",
       "2                   0.304124      0.681289     0.258832           0.318707   \n",
       "3                   0.046900      0.716788     0.272949           0.485765   \n",
       "4                   0.155033      0.652722     0.273291           0.379061   \n",
       "...                      ...           ...          ...                ...   \n",
       "4270                0.446232      0.571405     0.165541           0.119023   \n",
       "4271                0.193622      0.796267     0.229601           0.421859   \n",
       "4272                0.163496      0.735336     0.118362           0.311484   \n",
       "4273                0.155033      0.652722     0.273291           0.379061   \n",
       "4274                0.155033      0.652722     0.273291           0.379061   \n",
       "\n",
       "      gsv_contrast_std  gsv_coherence_std  \n",
       "0             0.195787           0.205824  \n",
       "1             0.195787           0.205824  \n",
       "2             0.243122           0.278741  \n",
       "3             0.234291           0.042244  \n",
       "4             0.195787           0.205824  \n",
       "...                ...                ...  \n",
       "4270          0.138799           0.121806  \n",
       "4271          0.242305           0.154616  \n",
       "4272          0.099330           0.094039  \n",
       "4273          0.195787           0.205824  \n",
       "4274          0.195787           0.205824  \n",
       "\n",
       "[4275 rows x 22 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ed24721-5860-4f55-9f76-dedb59bdeee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X/y dataframes\n",
    "y = ams.income\n",
    "X = preds.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb32d7a2-46c9-4a41-8777-a95044b88a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         00-20 low\n",
       "1         00-20 low\n",
       "2         00-20 low\n",
       "3         00-20 low\n",
       "4         00-20 low\n",
       "           ...     \n",
       "4270    80-100 high\n",
       "4271    80-100 high\n",
       "4272    80-100 high\n",
       "4273    80-100 high\n",
       "4274    80-100 high\n",
       "Name: income, Length: 4275, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b130b6ba-fe22-487f-9bcb-9520cd4ed02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './inc_ams'\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "# We will be able to work with files with/without header and\n",
    "# with different separators.\n",
    "\n",
    "ams.to_csv(\n",
    "    os.path.join(dataset_dir, 'train.csv'),\n",
    "    index=False, sep=',', header=True\n",
    ")\n",
    "preds.to_csv(\n",
    "    os.path.join(dataset_dir, 'preds.csv'),\n",
    "    index=False, sep=',', header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce1d7e52-0eeb-44d4-b953-a679606afe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape\n",
      "dataset 1:(4275, 21)\n",
      "\n",
      "\n",
      "Column names\n",
      "dataset 1:\n",
      "['gsv_apartments', 'gsv_commercial', 'gsv_greenery', 'gsv_historical', 'gsv_impervious', 'gsv_industrial', 'gsv_other', 'gsv_private', 'gsv_water', 'gsv_colour_hue_mean', 'gsv_colour_hue_std', 'gsv_colour_saturation_std', 'gsv_colour_brightness_mean', 'gsv_colour_brightness_std', 'gsv_disorderliness_mean', 'gsv_disorderliness_std', 'gsv_std_mean', 'gsv_std_std', 'gsv_contrast_mean', 'gsv_contrast_std', 'gsv_coherence_std']\n"
     ]
    }
   ],
   "source": [
    "pool1 = Pool(data=X, label=y)\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 1:' + str(pool1.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('dataset 1:')\n",
    "print(pool1.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7621cfa3-ec15-4d85-84f7-362fca40414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05b8b8b2-a53a-4168-ac25-288ffced2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   depth   | iterat... | l2_lea... | learni... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.554    \u001b[0m | \u001b[0m1.094e+03\u001b[0m | \u001b[0m6.727    \u001b[0m | \u001b[0m0.05731  \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.2175   \u001b[0m | \u001b[95m2.153    \u001b[0m | \u001b[95m1.25e+03 \u001b[0m | \u001b[95m31.47    \u001b[0m | \u001b[95m0.05888  \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.548    \u001b[0m | \u001b[0m838.7    \u001b[0m | \u001b[0m11.62    \u001b[0m | \u001b[0m0.05067  \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.2161   \u001b[0m | \u001b[0m2.773    \u001b[0m | \u001b[0m1.523e+03\u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.05085  \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.2048   \u001b[0m | \u001b[0m2.569    \u001b[0m | \u001b[0m507.9    \u001b[0m | \u001b[0m105.1    \u001b[0m | \u001b[0m0.06201  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.945    \u001b[0m | \u001b[0m1.838e+03\u001b[0m | \u001b[0m82.14    \u001b[0m | \u001b[0m0.09013  \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.193    \u001b[0m | \u001b[0m1.704e+03\u001b[0m | \u001b[0m3.786    \u001b[0m | \u001b[0m0.09284  \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.2155   \u001b[0m | \u001b[0m2.669    \u001b[0m | \u001b[0m1.613e+03\u001b[0m | \u001b[0m115.9    \u001b[0m | \u001b[0m0.04598  \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.2163   \u001b[0m | \u001b[0m2.315    \u001b[0m | \u001b[0m1.237e+03\u001b[0m | \u001b[0m36.18    \u001b[0m | \u001b[0m0.05873  \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.2028   \u001b[0m | \u001b[0m2.293    \u001b[0m | \u001b[0m853.8    \u001b[0m | \u001b[0m84.25    \u001b[0m | \u001b[0m0.04122  \u001b[0m |\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m0.22     \u001b[0m | \u001b[95m2.459    \u001b[0m | \u001b[95m1.404e+03\u001b[0m | \u001b[95m14.12    \u001b[0m | \u001b[95m0.04615  \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.2018   \u001b[0m | \u001b[0m2.262    \u001b[0m | \u001b[0m1.398e+03\u001b[0m | \u001b[0m109.3    \u001b[0m | \u001b[0m0.0263   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.986    \u001b[0m | \u001b[0m1.531e+03\u001b[0m | \u001b[0m67.42    \u001b[0m | \u001b[0m0.09476  \u001b[0m |\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m0.2214   \u001b[0m | \u001b[95m2.671    \u001b[0m | \u001b[95m1.407e+03\u001b[0m | \u001b[95m49.22    \u001b[0m | \u001b[95m0.05841  \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.2113   \u001b[0m | \u001b[0m2.968    \u001b[0m | \u001b[0m582.1    \u001b[0m | \u001b[0m109.6    \u001b[0m | \u001b[0m0.08624  \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.2109   \u001b[0m | \u001b[0m2.953    \u001b[0m | \u001b[0m503.9    \u001b[0m | \u001b[0m110.2    \u001b[0m | \u001b[0m0.08414  \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.2126   \u001b[0m | \u001b[0m2.552    \u001b[0m | \u001b[0m1.605e+03\u001b[0m | \u001b[0m112.4    \u001b[0m | \u001b[0m0.0325   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.981    \u001b[0m | \u001b[0m1.337e+03\u001b[0m | \u001b[0m58.98    \u001b[0m | \u001b[0m0.06405  \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.2173   \u001b[0m | \u001b[0m2.603    \u001b[0m | \u001b[0m1.41e+03 \u001b[0m | \u001b[0m116.3    \u001b[0m | \u001b[0m0.06579  \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.208    \u001b[0m | \u001b[0m2.343    \u001b[0m | \u001b[0m778.4    \u001b[0m | \u001b[0m105.4    \u001b[0m | \u001b[0m0.08199  \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.1864   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.477e+03\u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.1883   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m902.1    \u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m0.0176   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.2093   \u001b[0m | \u001b[0m2.085    \u001b[0m | \u001b[0m649.0    \u001b[0m | \u001b[0m113.4    \u001b[0m | \u001b[0m0.09962  \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.2187   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m619.2    \u001b[0m | \u001b[0m55.13    \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.2156   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m689.3    \u001b[0m | \u001b[0m59.5     \u001b[0m | \u001b[0m0.06518  \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.2094   \u001b[0m | \u001b[0m2.397    \u001b[0m | \u001b[0m1.409e+03\u001b[0m | \u001b[0m115.8    \u001b[0m | \u001b[0m0.04966  \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.2083   \u001b[0m | \u001b[0m2.072    \u001b[0m | \u001b[0m1.434e+03\u001b[0m | \u001b[0m90.3     \u001b[0m | \u001b[0m0.04586  \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.1843   \u001b[0m | \u001b[0m2.382    \u001b[0m | \u001b[0m652.3    \u001b[0m | \u001b[0m72.12    \u001b[0m | \u001b[0m0.01166  \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.1861   \u001b[0m | \u001b[0m2.767    \u001b[0m | \u001b[0m579.0    \u001b[0m | \u001b[0m62.08    \u001b[0m | \u001b[0m0.01459  \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.1981   \u001b[0m | \u001b[0m2.737    \u001b[0m | \u001b[0m1.439e+03\u001b[0m | \u001b[0m119.2    \u001b[0m | \u001b[0m0.01472  \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.2158   \u001b[0m | \u001b[0m2.739    \u001b[0m | \u001b[0m1.443e+03\u001b[0m | \u001b[0m28.25    \u001b[0m | \u001b[0m0.02919  \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.2051   \u001b[0m | \u001b[0m2.314    \u001b[0m | \u001b[0m724.1    \u001b[0m | \u001b[0m88.9     \u001b[0m | \u001b[0m0.05673  \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.1996   \u001b[0m | \u001b[0m2.202    \u001b[0m | \u001b[0m726.8    \u001b[0m | \u001b[0m40.03    \u001b[0m | \u001b[0m0.02959  \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m652.7    \u001b[0m | \u001b[0m19.94    \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.2034   \u001b[0m | \u001b[0m2.468    \u001b[0m | \u001b[0m614.8    \u001b[0m | \u001b[0m92.24    \u001b[0m | \u001b[0m0.06344  \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.2047   \u001b[0m | \u001b[0m2.119    \u001b[0m | \u001b[0m688.2    \u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m0.06584  \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.1875   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.553e+03\u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.2087   \u001b[0m | \u001b[0m2.795    \u001b[0m | \u001b[0m820.4    \u001b[0m | \u001b[0m119.4    \u001b[0m | \u001b[0m0.04935  \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.151    \u001b[0m | \u001b[0m1.229e+03\u001b[0m | \u001b[0m1.435    \u001b[0m | \u001b[0m0.0703   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.2073   \u001b[0m | \u001b[0m2.098    \u001b[0m | \u001b[0m1.248e+03\u001b[0m | \u001b[0m65.28    \u001b[0m | \u001b[0m0.03493  \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.2138   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m766.1    \u001b[0m | \u001b[0m63.41    \u001b[0m | \u001b[0m0.08477  \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.1886   \u001b[0m | \u001b[0m2.095    \u001b[0m | \u001b[0m807.8    \u001b[0m | \u001b[0m81.05    \u001b[0m | \u001b[0m0.01824  \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.1899   \u001b[0m | \u001b[0m2.421    \u001b[0m | \u001b[0m1.634e+03\u001b[0m | \u001b[0m80.87    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.2166   \u001b[0m | \u001b[0m2.785    \u001b[0m | \u001b[0m1.204e+03\u001b[0m | \u001b[0m73.03    \u001b[0m | \u001b[0m0.06166  \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.209    \u001b[0m | \u001b[0m2.196    \u001b[0m | \u001b[0m1.218e+03\u001b[0m | \u001b[0m113.5    \u001b[0m | \u001b[0m0.05632  \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.2135   \u001b[0m | \u001b[0m2.508    \u001b[0m | \u001b[0m1.173e+03\u001b[0m | \u001b[0m101.8    \u001b[0m | \u001b[0m0.04465  \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.1905   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m1.163e+03\u001b[0m | \u001b[0m62.64    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.1978   \u001b[0m | \u001b[0m2.273    \u001b[0m | \u001b[0m1.13e+03 \u001b[0m | \u001b[0m118.7    \u001b[0m | \u001b[0m0.02467  \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.1912   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m1.666e+03\u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.1948   \u001b[0m | \u001b[0m2.692    \u001b[0m | \u001b[0m541.7    \u001b[0m | \u001b[0m118.0    \u001b[0m | \u001b[0m0.03506  \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.2075   \u001b[0m | \u001b[0m2.429    \u001b[0m | \u001b[0m1.264e+03\u001b[0m | \u001b[0m118.8    \u001b[0m | \u001b[0m0.05211  \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.2175   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m859.4    \u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.1911   \u001b[0m | \u001b[0m2.229    \u001b[0m | \u001b[0m1.074e+03\u001b[0m | \u001b[0m120.0    \u001b[0m | \u001b[0m0.01971  \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m2.735    \u001b[0m | \u001b[0m1.472e+03\u001b[0m | \u001b[0m1.876    \u001b[0m | \u001b[0m0.06458  \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.2185   \u001b[0m | \u001b[0m2.361    \u001b[0m | \u001b[0m1.439e+03\u001b[0m | \u001b[0m56.44    \u001b[0m | \u001b[0m0.07072  \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.1846   \u001b[0m | \u001b[0m2.083    \u001b[0m | \u001b[0m1.017e+03\u001b[0m | \u001b[0m115.5    \u001b[0m | \u001b[0m0.01033  \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.2191   \u001b[0m | \u001b[0m2.776    \u001b[0m | \u001b[0m960.6    \u001b[0m | \u001b[0m85.38    \u001b[0m | \u001b[0m0.09035  \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.1854   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m923.6    \u001b[0m | \u001b[0m67.32    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.2192   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m987.3    \u001b[0m | \u001b[0m54.28    \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.2067   \u001b[0m | \u001b[0m2.744    \u001b[0m | \u001b[0m958.7    \u001b[0m | \u001b[0m21.94    \u001b[0m | \u001b[0m0.02195  \u001b[0m |\n",
      "=========================================================================\n",
      "Best hyperparameters found were:\n",
      "{'depth': 3, 'iterations': 1407, 'l2_leaf_reg': 49, 'learning_rate': 0.05841076133949613}\n",
      "Parameters: learning_rate=0.05887838420825597, iterations=1250, depth=2, l2_leaf_reg=31\n",
      "Average Train F1 Score: 0.2948162844169904, Average Validation F1 Score: 0.21746103770770137, F1 Score Difference: 0.07735524670928906\n",
      "\n",
      "Parameters: learning_rate=0.05084604967186924, iterations=1523, depth=3, l2_leaf_reg=104\n",
      "Average Train F1 Score: 0.2894214504982487, Average Validation F1 Score: 0.2160991146010626, F1 Score Difference: 0.07332233589718609\n",
      "\n",
      "Parameters: learning_rate=0.06200914112479512, iterations=507, depth=3, l2_leaf_reg=105\n",
      "Average Train F1 Score: 0.24549206584964703, Average Validation F1 Score: 0.2048108584294898, F1 Score Difference: 0.04068120742015724\n",
      "\n",
      "Parameters: learning_rate=0.04598442966835719, iterations=1613, depth=3, l2_leaf_reg=116\n",
      "Average Train F1 Score: 0.2898084455050922, Average Validation F1 Score: 0.21552828418337877, F1 Score Difference: 0.07428016132171344\n",
      "\n",
      "Parameters: learning_rate=0.058729321404306166, iterations=1236, depth=2, l2_leaf_reg=36\n",
      "Average Train F1 Score: 0.28915101667685816, Average Validation F1 Score: 0.2162507349531865, F1 Score Difference: 0.07290028172367166\n",
      "\n",
      "Parameters: learning_rate=0.04121907830043984, iterations=853, depth=2, l2_leaf_reg=84\n",
      "Average Train F1 Score: 0.22817277759490356, Average Validation F1 Score: 0.20277745090950122, F1 Score Difference: 0.025395326685402342\n",
      "\n",
      "Parameters: learning_rate=0.04614962143680817, iterations=1403, depth=2, l2_leaf_reg=14\n",
      "Average Train F1 Score: 0.2983874700109424, Average Validation F1 Score: 0.21997027403380978, F1 Score Difference: 0.07841719597713262\n",
      "\n",
      "Parameters: learning_rate=0.026297186456882178, iterations=1397, depth=2, l2_leaf_reg=109\n",
      "Average Train F1 Score: 0.22715800210499687, Average Validation F1 Score: 0.20175343558343273, F1 Score Difference: 0.025404566521564143\n",
      "\n",
      "Parameters: learning_rate=0.05841076133949613, iterations=1407, depth=3, l2_leaf_reg=49\n",
      "Average Train F1 Score: 0.3208867195136097, Average Validation F1 Score: 0.22144069735763713, F1 Score Difference: 0.09944602215597256\n",
      "\n",
      "Parameters: learning_rate=0.08623743325283238, iterations=582, depth=3, l2_leaf_reg=110\n",
      "Average Train F1 Score: 0.2729920850124537, Average Validation F1 Score: 0.2112972594348974, F1 Score Difference: 0.06169482557755629\n",
      "\n",
      "Parameters: learning_rate=0.08413696103753317, iterations=503, depth=3, l2_leaf_reg=110\n",
      "Average Train F1 Score: 0.2619045543954116, Average Validation F1 Score: 0.21094944223754358, F1 Score Difference: 0.05095511215786802\n",
      "\n",
      "Parameters: learning_rate=0.03250237068880352, iterations=1605, depth=3, l2_leaf_reg=112\n",
      "Average Train F1 Score: 0.2761636850901801, Average Validation F1 Score: 0.2125529168066691, F1 Score Difference: 0.06361076828351098\n",
      "\n",
      "Parameters: learning_rate=0.06579190387311439, iterations=1410, depth=3, l2_leaf_reg=116\n",
      "Average Train F1 Score: 0.30097556738083125, Average Validation F1 Score: 0.21732223176913337, F1 Score Difference: 0.08365333561169788\n",
      "\n",
      "Parameters: learning_rate=0.08198977005405511, iterations=778, depth=2, l2_leaf_reg=105\n",
      "Average Train F1 Score: 0.253820226488345, Average Validation F1 Score: 0.20798490822732005, F1 Score Difference: 0.045835318261024965\n",
      "\n",
      "Parameters: learning_rate=0.01, iterations=1477, depth=2, l2_leaf_reg=120\n",
      "Average Train F1 Score: 0.1960696951089945, Average Validation F1 Score: 0.1864461159345905, F1 Score Difference: 0.009623579174403984\n",
      "\n",
      "Parameters: learning_rate=0.017604420419817406, iterations=902, depth=2, l2_leaf_reg=120\n",
      "Average Train F1 Score: 0.1995326367534372, Average Validation F1 Score: 0.18833535298111337, F1 Score Difference: 0.011197283772323818\n",
      "\n",
      "Parameters: learning_rate=0.0996242991777688, iterations=649, depth=2, l2_leaf_reg=113\n",
      "Average Train F1 Score: 0.25810941317074176, Average Validation F1 Score: 0.20927115924624268, F1 Score Difference: 0.04883825392449909\n",
      "\n",
      "Parameters: learning_rate=0.1, iterations=619, depth=3, l2_leaf_reg=55\n",
      "Average Train F1 Score: 0.29904925075963334, Average Validation F1 Score: 0.2186511850150903, F1 Score Difference: 0.08039806574454306\n",
      "\n",
      "Parameters: learning_rate=0.06518394369891228, iterations=689, depth=3, l2_leaf_reg=60\n",
      "Average Train F1 Score: 0.27775372346000793, Average Validation F1 Score: 0.21556629680438552, F1 Score Difference: 0.06218742665562241\n",
      "\n",
      "Parameters: learning_rate=0.049657434931097866, iterations=1408, depth=2, l2_leaf_reg=116\n",
      "Average Train F1 Score: 0.2608799283381688, Average Validation F1 Score: 0.20937270375777742, F1 Score Difference: 0.05150722458039139\n",
      "\n",
      "Parameters: learning_rate=0.045861029440874175, iterations=1433, depth=2, l2_leaf_reg=90\n",
      "Average Train F1 Score: 0.2522131627428144, Average Validation F1 Score: 0.2082729050537974, F1 Score Difference: 0.04394025768901702\n",
      "\n",
      "Parameters: learning_rate=0.011659363871444393, iterations=652, depth=2, l2_leaf_reg=72\n",
      "Average Train F1 Score: 0.18860518803175388, Average Validation F1 Score: 0.18426362893459103, F1 Score Difference: 0.004341559097162856\n",
      "\n",
      "Parameters: learning_rate=0.014593906395722382, iterations=579, depth=3, l2_leaf_reg=62\n",
      "Average Train F1 Score: 0.19515932922016402, Average Validation F1 Score: 0.18605660043365185, F1 Score Difference: 0.009102728786512165\n",
      "\n",
      "Parameters: learning_rate=0.014724714283612031, iterations=1438, depth=3, l2_leaf_reg=119\n",
      "Average Train F1 Score: 0.21933956151048167, Average Validation F1 Score: 0.19812494048396195, F1 Score Difference: 0.02121462102651972\n",
      "\n",
      "Parameters: learning_rate=0.029187515925727568, iterations=1443, depth=3, l2_leaf_reg=28\n",
      "Average Train F1 Score: 0.29928069586697087, Average Validation F1 Score: 0.21583491539667787, F1 Score Difference: 0.083445780470293\n",
      "\n",
      "Parameters: learning_rate=0.05673208435482071, iterations=724, depth=2, l2_leaf_reg=89\n",
      "Average Train F1 Score: 0.2303057128635487, Average Validation F1 Score: 0.20510581710737058, F1 Score Difference: 0.02519989575617812\n",
      "\n",
      "Parameters: learning_rate=0.02959105339551525, iterations=726, depth=2, l2_leaf_reg=40\n",
      "Average Train F1 Score: 0.2257629963857659, Average Validation F1 Score: 0.19960881749338955, F1 Score Difference: 0.026154178892376367\n",
      "\n",
      "Parameters: learning_rate=0.06343804265815474, iterations=614, depth=2, l2_leaf_reg=92\n",
      "Average Train F1 Score: 0.24088177969586394, Average Validation F1 Score: 0.20338689628076181, F1 Score Difference: 0.037494883415102126\n",
      "\n",
      "Parameters: learning_rate=0.06583743880584948, iterations=688, depth=2, l2_leaf_reg=100\n",
      "Average Train F1 Score: 0.245681317565302, Average Validation F1 Score: 0.2047031725184957, F1 Score Difference: 0.0409781450468063\n",
      "\n",
      "Parameters: learning_rate=0.01, iterations=1553, depth=2, l2_leaf_reg=120\n",
      "Average Train F1 Score: 0.19909015163842358, Average Validation F1 Score: 0.18745289993524017, F1 Score Difference: 0.011637251703183416\n",
      "\n",
      "Parameters: learning_rate=0.049352599628465534, iterations=820, depth=3, l2_leaf_reg=119\n",
      "Average Train F1 Score: 0.25337270029456377, Average Validation F1 Score: 0.20873228630927504, F1 Score Difference: 0.04464041398528873\n",
      "\n",
      "Parameters: learning_rate=0.03492708098503887, iterations=1248, depth=2, l2_leaf_reg=65\n",
      "Average Train F1 Score: 0.24014013832877498, Average Validation F1 Score: 0.20734763307122597, F1 Score Difference: 0.03279250525754901\n",
      "\n",
      "Parameters: learning_rate=0.0847745559049608, iterations=766, depth=2, l2_leaf_reg=63\n",
      "Average Train F1 Score: 0.2676749314248909, Average Validation F1 Score: 0.21383115839553685, F1 Score Difference: 0.05384377302935406\n",
      "\n",
      "Parameters: learning_rate=0.018244744023863065, iterations=807, depth=2, l2_leaf_reg=81\n",
      "Average Train F1 Score: 0.2028402948314565, Average Validation F1 Score: 0.18861537389762884, F1 Score Difference: 0.014224920933827656\n",
      "\n",
      "Parameters: learning_rate=0.01, iterations=1634, depth=2, l2_leaf_reg=81\n",
      "Average Train F1 Score: 0.20722520652702842, Average Validation F1 Score: 0.18986013028861506, F1 Score Difference: 0.01736507623841335\n",
      "\n",
      "Parameters: learning_rate=0.06166378127231861, iterations=1204, depth=3, l2_leaf_reg=73\n",
      "Average Train F1 Score: 0.30081521105646153, Average Validation F1 Score: 0.2165814933054897, F1 Score Difference: 0.08423371775097183\n",
      "\n",
      "Parameters: learning_rate=0.05632482347075609, iterations=1217, depth=2, l2_leaf_reg=113\n",
      "Average Train F1 Score: 0.26461168351392184, Average Validation F1 Score: 0.2089838136740517, F1 Score Difference: 0.05562786983987014\n",
      "\n",
      "Parameters: learning_rate=0.044654675742340735, iterations=1173, depth=3, l2_leaf_reg=102\n",
      "Average Train F1 Score: 0.27545156498098966, Average Validation F1 Score: 0.21352081550437982, F1 Score Difference: 0.06193074947660984\n",
      "\n",
      "Parameters: learning_rate=0.01, iterations=1162, depth=3, l2_leaf_reg=63\n",
      "Average Train F1 Score: 0.2005523076869351, Average Validation F1 Score: 0.19047651431532242, F1 Score Difference: 0.010075793371612685\n",
      "\n",
      "Parameters: learning_rate=0.024671058034576365, iterations=1129, depth=2, l2_leaf_reg=119\n",
      "Average Train F1 Score: 0.2131691807838587, Average Validation F1 Score: 0.19776028851591437, F1 Score Difference: 0.01540889226794434\n",
      "\n",
      "Parameters: learning_rate=0.01, iterations=1665, depth=3, l2_leaf_reg=120\n",
      "Average Train F1 Score: 0.21039336739671954, Average Validation F1 Score: 0.19123911655590267, F1 Score Difference: 0.019154250840816872\n",
      "\n",
      "Parameters: learning_rate=0.035056703507751356, iterations=541, depth=3, l2_leaf_reg=118\n",
      "Average Train F1 Score: 0.21782849507025817, Average Validation F1 Score: 0.19475615230237306, F1 Score Difference: 0.023072342767885112\n",
      "\n",
      "Parameters: learning_rate=0.05210565632581113, iterations=1264, depth=2, l2_leaf_reg=119\n",
      "Average Train F1 Score: 0.254516633283961, Average Validation F1 Score: 0.2075080471804071, F1 Score Difference: 0.04700858610355391\n",
      "\n",
      "Parameters: learning_rate=0.1, iterations=859, depth=3, l2_leaf_reg=120\n",
      "Average Train F1 Score: 0.3009786557044406, Average Validation F1 Score: 0.21750294403136367, F1 Score Difference: 0.08347571167307694\n",
      "\n",
      "Parameters: learning_rate=0.019708705766250924, iterations=1074, depth=2, l2_leaf_reg=120\n",
      "Average Train F1 Score: 0.20931149712054292, Average Validation F1 Score: 0.19108393290070033, F1 Score Difference: 0.01822756421984259\n",
      "\n",
      "Parameters: learning_rate=0.07071543992154845, iterations=1439, depth=2, l2_leaf_reg=56\n",
      "Average Train F1 Score: 0.2883446292169116, Average Validation F1 Score: 0.21853354363752966, F1 Score Difference: 0.06981108557938195\n",
      "\n",
      "Parameters: learning_rate=0.010328228911984488, iterations=1017, depth=2, l2_leaf_reg=115\n",
      "Average Train F1 Score: 0.18979760083177702, Average Validation F1 Score: 0.184632152188626, F1 Score Difference: 0.005165448643151022\n",
      "\n",
      "Parameters: learning_rate=0.09035108942454428, iterations=960, depth=3, l2_leaf_reg=85\n",
      "Average Train F1 Score: 0.30697522387654097, Average Validation F1 Score: 0.21905435773838508, F1 Score Difference: 0.08792086613815589\n",
      "\n",
      "Parameters: learning_rate=0.01, iterations=923, depth=2, l2_leaf_reg=67\n",
      "Average Train F1 Score: 0.1894311942408476, Average Validation F1 Score: 0.18539246628604408, F1 Score Difference: 0.004038727954803506\n",
      "\n",
      "Parameters: learning_rate=0.1, iterations=987, depth=2, l2_leaf_reg=54\n",
      "Average Train F1 Score: 0.2872659965688014, Average Validation F1 Score: 0.2192212525894762, F1 Score Difference: 0.06804474397932522\n",
      "\n",
      "Parameters: learning_rate=0.02194706962715812, iterations=958, depth=3, l2_leaf_reg=22\n",
      "Average Train F1 Score: 0.2583388049878391, Average Validation F1 Score: 0.20673982800507962, F1 Score Difference: 0.051598976982759504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters optimization\n",
    "# Define the function to optimize\n",
    "def catboost_cv(learning_rate, iterations, depth, l2_leaf_reg):\n",
    "    # Convert continuous parameters to integer where necessary\n",
    "    iterations = int(iterations)\n",
    "    depth = int(round(depth))\n",
    "    l2_leaf_reg = int(round(l2_leaf_reg))\n",
    "    \n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    train_f1_scores = []\n",
    "    validation_f1_scores = []\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        train_pool = Pool(data=X_train_fold, label=y_train_fold)\n",
    "        test_pool = Pool(data=X_test_fold, label=y_test_fold)\n",
    "        \n",
    "        # Define and train the model\n",
    "        model = CatBoostClassifier(\n",
    "            learning_rate=learning_rate,\n",
    "            iterations=iterations,\n",
    "            depth=depth,\n",
    "            l2_leaf_reg=l2_leaf_reg,\n",
    "            loss_function='MultiClass',\n",
    "            eval_metric='TotalF1',\n",
    "            random_seed=42,\n",
    "            logging_level='Silent'\n",
    "        )\n",
    "        \n",
    "        model.fit(train_pool, eval_set=test_pool, use_best_model=True)\n",
    "        \n",
    "        # Predict on training and validation data\n",
    "        y_train_pred = model.predict(X_train_fold)\n",
    "        y_test_pred = model.predict(X_test_fold)\n",
    "        \n",
    "        # Calculate F1 scores\n",
    "        train_f1 = f1_score(y_train_fold, y_train_pred, average='weighted')\n",
    "        validation_f1 = f1_score(y_test_fold, y_test_pred, average='weighted')\n",
    "        \n",
    "        train_f1_scores.append(train_f1)\n",
    "        validation_f1_scores.append(validation_f1)\n",
    "    \n",
    "    # Calculate average F1 scores across all folds\n",
    "    avg_train_f1 = np.mean(train_f1_scores)\n",
    "    avg_validation_f1 = np.mean(validation_f1_scores)\n",
    "    \n",
    "    # Calculate the difference between training and validation F1 scores\n",
    "    f1_difference = avg_train_f1 - avg_validation_f1\n",
    "    \n",
    "    # Return a very low score if the F1 difference exceeds 0.1\n",
    "    if f1_difference > 0.1:\n",
    "        return 0\n",
    "    \n",
    "    # Store the results for comparison\n",
    "    results.append({\n",
    "        'learning_rate': learning_rate,\n",
    "        'iterations': iterations,\n",
    "        'depth': depth,\n",
    "        'l2_leaf_reg': l2_leaf_reg,\n",
    "        'avg_train_f1': avg_train_f1,\n",
    "        'avg_validation_f1': avg_validation_f1,\n",
    "        'f1_difference': f1_difference\n",
    "    })\n",
    "    \n",
    "    return avg_validation_f1\n",
    "\n",
    "# Define the initial bounds for hyperparameters\n",
    "param_bounds = {\n",
    "    'learning_rate': (0.01, 0.1), \n",
    "    'iterations': (500, 2000), \n",
    "    'depth': (2, 3), \n",
    "    'l2_leaf_reg': (1, 120)\n",
    "}\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Initialize Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=catboost_cv,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=63,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform optimization\n",
    "optimizer.maximize(\n",
    "    init_points=20,  # Number of initial random points\n",
    "    n_iter=40       # Number of optimization iterations\n",
    ")\n",
    "\n",
    "# Extract the best parameters\n",
    "best_params = optimizer.max['params']\n",
    "best_params['iterations'] = int(best_params['iterations'])\n",
    "best_params['depth'] = int(round(best_params['depth']))\n",
    "best_params['l2_leaf_reg'] = int(round(best_params['l2_leaf_reg']))\n",
    "\n",
    "print(\"Best hyperparameters found were:\")\n",
    "print(best_params)\n",
    "\n",
    "# Print train/test F1 score comparison\n",
    "for result in results:\n",
    "    print(f\"Parameters: learning_rate={result['learning_rate']}, iterations={result['iterations']}, depth={result['depth']}, l2_leaf_reg={result['l2_leaf_reg']}\")\n",
    "    print(f\"Average Train F1 Score: {result['avg_train_f1']}, Average Validation F1 Score: {result['avg_validation_f1']}, F1 Score Difference: {result['f1_difference']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50982629-f748-475f-a71e-6b1b9957b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CatBoost classifier instance\n",
    "tuned_model = CatBoostClassifier(\n",
    "    random_seed=64,\n",
    "    iterations=1407,\n",
    "    task_type=\"CPU\",\n",
    "    learning_rate=0.05841076133949613,\n",
    "    l2_leaf_reg=49,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "tuned_model.fit(\n",
    "    X_train, y_train,\n",
    "    verbose=False,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    early_stopping_rounds=50,  # Stops if the chosen metric doesn't improve in 50 rounds\n",
    "    plot=False  # Plots the metric during training\n",
    ")\n",
    "\n",
    "# Get results of the evaluation\n",
    "results = tuned_model.get_evals_result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db04bd1e-3735-49d0-bcc1-3deeb5a52dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Accuracy: 0.345906432748538\n",
      "Train Accuracy Standard Deviation: 0.023182297576416728\n",
      "Average Test Accuracy: 0.304327485380117\n",
      "Test Accuracy Standard Deviation: 0.011974841487628589\n",
      "Average Train F1 Score: 0.19250908708645878\n",
      "Train F1 Score Standard Deviation: 0.03521282858943335\n",
      "Average Test F1 Score: 0.15114081900392243\n",
      "Test F1 Score Standard Deviation: 0.013036339761004967\n",
      "Average Train AUC: 0.6280371747659064\n",
      "Train AUC Standard Deviation: 0.02495290799893737\n",
      "Average Test AUC: 0.5459801120988257\n",
      "Test AUC Standard Deviation: 0.011611691943695608\n"
     ]
    }
   ],
   "source": [
    "# Quality assessment\n",
    "# Define the model with optimal parameters\n",
    "tuned_model = CatBoostClassifier(\n",
    "    random_seed=64,\n",
    "    iterations=1407,\n",
    "    task_type=\"CPU\",\n",
    "    learning_rate=0.05841076133949613,\n",
    "    l2_leaf_reg=49,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "\n",
    "# Setup Repeated K-Fold cross-validation\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# Prepare lists to store results\n",
    "train_accuracy_results = []\n",
    "test_accuracy_results = []\n",
    "train_f1_results = []\n",
    "test_f1_results = []\n",
    "train_auc_results = []\n",
    "test_auc_results = []\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in rkf.split(X):\n",
    "    train_pool = Pool(X.iloc[train_index], y.iloc[train_index])\n",
    "    test_pool = Pool(X.iloc[test_index], y.iloc[test_index])\n",
    "\n",
    "    # Fit model\n",
    "    tuned_model.fit(train_pool, eval_set=test_pool, verbose=False)\n",
    "\n",
    "    # Predict on train and test sets\n",
    "    train_predictions = tuned_model.predict(train_pool)\n",
    "    test_predictions = tuned_model.predict(test_pool)\n",
    "    \n",
    "    # Predict probabilities for AUC calculation\n",
    "    train_probabilities = tuned_model.predict_proba(train_pool)\n",
    "    test_probabilities = tuned_model.predict_proba(test_pool)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    train_accuracy = accuracy_score(y.iloc[train_index], train_predictions)\n",
    "    test_accuracy = accuracy_score(y.iloc[test_index], test_predictions)\n",
    "    train_accuracy_results.append(train_accuracy)\n",
    "    test_accuracy_results.append(test_accuracy)\n",
    "\n",
    "    # Calculate F1 Score (macro)\n",
    "    train_f1 = f1_score(y.iloc[train_index], train_predictions, average='macro')\n",
    "    test_f1 = f1_score(y.iloc[test_index], test_predictions, average='macro')\n",
    "    train_f1_results.append(train_f1)\n",
    "    test_f1_results.append(test_f1)\n",
    "\n",
    "    # Calculate AUC (macro, multi_class='ovr')\n",
    "    train_auc = roc_auc_score(y.iloc[train_index], train_probabilities, multi_class='ovr', average='macro')\n",
    "    test_auc = roc_auc_score(y.iloc[test_index], test_probabilities, multi_class='ovr', average='macro')\n",
    "    train_auc_results.append(train_auc)\n",
    "    test_auc_results.append(test_auc)\n",
    "\n",
    "# Calculate the average and standard deviation of metrics across all train and test folds\n",
    "mean_train_accuracy = np.mean(train_accuracy_results)\n",
    "std_train_accuracy = np.std(train_accuracy_results)\n",
    "mean_test_accuracy = np.mean(test_accuracy_results)\n",
    "std_test_accuracy = np.std(test_accuracy_results)\n",
    "\n",
    "mean_train_f1 = np.mean(train_f1_results)\n",
    "std_train_f1 = np.std(train_f1_results)\n",
    "mean_test_f1 = np.mean(test_f1_results)\n",
    "std_test_f1 = np.std(test_f1_results)\n",
    "\n",
    "mean_train_auc = np.mean(train_auc_results)\n",
    "std_train_auc = np.std(train_auc_results)\n",
    "mean_test_auc = np.mean(test_auc_results)\n",
    "std_test_auc = np.std(test_auc_results)\n",
    "\n",
    "print(\"Average Train Accuracy:\", mean_train_accuracy)\n",
    "print(\"Train Accuracy Standard Deviation:\", std_train_accuracy)\n",
    "print(\"Average Test Accuracy:\", mean_test_accuracy)\n",
    "print(\"Test Accuracy Standard Deviation:\", std_test_accuracy)\n",
    "print(\"Average Train F1 Score:\", mean_train_f1)\n",
    "print(\"Train F1 Score Standard Deviation:\", std_train_f1)\n",
    "print(\"Average Test F1 Score:\", mean_test_f1)\n",
    "print(\"Test F1 Score Standard Deviation:\", std_test_f1)\n",
    "print(\"Average Train AUC:\", mean_train_auc)\n",
    "print(\"Train AUC Standard Deviation:\", std_train_auc)\n",
    "print(\"Average Test AUC:\", mean_test_auc)\n",
    "print(\"Test AUC Standard Deviation:\", std_test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "570807c1-77d4-4abd-b60d-b29d5115b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "class_names = ['00-20 low', '20-40 below average', '40-60 average', '60-80 above average', '80-100 high']\n",
    "\n",
    "# Ensure 'y' is a single-column DataFrame and convert it to a Series\n",
    "if isinstance(y, pd.DataFrame):\n",
    "    y = y.iloc[:, 0]\n",
    "\n",
    "# Make predictions using the CatBoost model\n",
    "predicted_values = tuned_model.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y, predicted_values) * 100\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, predicted_values, labels=class_names)\n",
    "\n",
    "# Transpose the confusion matrix\n",
    "conf_matrix = conf_matrix.T\n",
    "\n",
    "# Plot confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))  # Create a figure and axis\n",
    "disp.plot(cmap='Blues', xticks_rotation='vertical', ax=ax)\n",
    "ax.set_title(f'\\nAccuracy: {accuracy:.2f}%')\n",
    "ax.set_xlabel('Actual income classes in Amsterdam')\n",
    "ax.set_ylabel('Predicted income classes in Amsterdam')\n",
    "\n",
    "# Save the plot as an SVG file\n",
    "plt.savefig('confusion_matrix_ams_gsv.svg', format='svg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cb01d-fe1d-440b-bd95-2c93922208a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting SHAP values\n",
    "if isinstance(y, pd.DataFrame):\n",
    "    y = y.iloc[:, 0]\n",
    "\n",
    "# Convert 'y' to a numpy array\n",
    "y = np.array(y)\n",
    "\n",
    "# Initialize the SHAP explainer\n",
    "explainer = shap.TreeExplainer(tuned_model)\n",
    "\n",
    "# Calculate SHAP values for the dataset\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# For categorical targets, SHAP returns a list of arrays (one for each class)\n",
    "# We will focus on the class '80-100 high'\n",
    "target_class_index = class_names.index('80-100 high')\n",
    "shap_values_for_class = shap_values[target_class_index]\n",
    "\n",
    "# Ensure shap_values_for_class is a DataFrame\n",
    "shap_df = pd.DataFrame(shap_values_for_class, columns=X.columns)\n",
    "\n",
    "# Extract SHAP values for the specific predictor 'colour_hue_disorderliness_mean'\n",
    "shap_tcap_wetness_mean = shap_df['tcap_wetness_mean']\n",
    "shap_colour_brightness_coherence_mean = shap_df['colour_brightness_coherence_mean']\n",
    "shap_tcap_wetness_disorderliness_mean = shap_df['tcap_wetness_disorderliness_mean']\n",
    "shap_surface_roughness_disorderliness_mean = shap_df['surface_roughness_disorderliness_mean']\n",
    "shap_ndwi_wetness_contrast_mean = shap_df['ndwi_wetness_contrast_mean']\n",
    "shap_ndwi_wetness_coherence_std = shap_df['ndwi_wetness_coherence_std']\n",
    "# Ensure all arrays are 1-dimensional\n",
    "y = y.flatten()\n",
    "predicted_values = tuned_model.predict(X).flatten()\n",
    "shap_tcap_wetness_mean = shap_tcap_wetness_mean.values.flatten()\n",
    "shap_colour_brightness_coherence_mean = shap_colour_brightness_coherence_mean.values.flatten()\n",
    "shap_tcap_wetness_disorderliness_mean = shap_tcap_wetness_disorderliness_mean.values.flatten()\n",
    "shap_surface_roughness_disorderliness_mean = shap_surface_roughness_disorderliness_mean.values.flatten()\n",
    "shap_ndwi_wetness_contrast_mean = shap_ndwi_wetness_contrast_mean.values.flatten()\n",
    "shap_ndwi_wetness_coherence_std = shap_ndwi_wetness_coherence_std.values.flatten()\n",
    "\n",
    "# Create a DataFrame with actual values, predicted values, and SHAP values for 'colour_hue_disorderliness_mean'\n",
    "results_with_shap_df = pd.DataFrame({\n",
    "    'Actual': y,\n",
    "    'Predicted': predicted_values,\n",
    "    'SHAP_tcap_wetness_mean': shap_tcap_wetness_mean,\n",
    "    'SHAP_colour_brightness_coherence_mean': shap_colour_brightness_coherence_mean,\n",
    "    'SHAP_tcap_wetness_disorderliness_mean': shap_tcap_wetness_disorderliness_mean,\n",
    "    'SHAP_surface_roughness_disorderliness_mean': shap_surface_roughness_disorderliness_mean,\n",
    "    'SHAP_ndwi_wetness_contrast_mean': shap_ndwi_wetness_contrast_mean,\n",
    "    'SHAP_ndwi_wetness_coherence_std': shap_ndwi_wetness_coherence_std\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results_with_shap_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323fb20-32b7-4246-9b62-26f11544aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = results_with_shap_df.join(income, how='inner')  # Use 'inner' join to keep only matching indices\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd052a-f246-49bd-962a-79cda3fd0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.join(id, how='inner')  # Use 'inner' join to keep only matching indices\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddbb9d-f0e9-4eab-8954-7365496cf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors assessment\n",
    "# Define the categories and their order\n",
    "categories = ['00-20 low', '20-40 below average', '40-60 average', '60-80 above average', '80-100 high']\n",
    "\n",
    "# Define the function to calculate the error\n",
    "def calculate_error(actual, predicted, categories):\n",
    "    actual_index = categories.index(actual)\n",
    "    predicted_index = categories.index(predicted)\n",
    "    difference = predicted_index - actual_index\n",
    "    \n",
    "    if difference == 0:\n",
    "        return 'accurate'\n",
    "    elif difference > 0:\n",
    "        return f'overestimated {difference} class{\"es\" if difference > 1 else \"\"}'\n",
    "    else:\n",
    "        return f'underestimated {abs(difference)} class{\"es\" if abs(difference) > 1 else \"\"}'\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "combined_df['Error'] = combined_df.apply(lambda row: calculate_error(row['Actual'], row['Predicted'], categories), axis=1)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7752f07-2383-4f28-9b3e-1d8380e88a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('pred_vs_actual_with_shap_and_id_ams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e054fe5-cce3-4468-8831-59a6128d3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting iterations\n",
    "epochs = np.arange(len(results['learn']['MultiClass']))\n",
    "\n",
    "# Retrieve the best iteration from the model\n",
    "best_iteration = tuned_model.get_best_iteration()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, results['learn']['MultiClass'], label='Train')\n",
    "plt.plot(epochs, results['validation']['MultiClass'], label='Validation')\n",
    "\n",
    "# Mark the best iteration on the plot\n",
    "if best_iteration is not None:\n",
    "    plt.scatter(best_iteration, results['validation']['MultiClass'][best_iteration], color='red', zorder=5, label='Best iteration')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MultiClass')\n",
    "plt.title('Learning curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c8e96f1-a78d-423c-ae69-bfdff6b6ec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape\n",
      "dataset 1:(4275, 21)\n",
      "\n",
      "\n",
      "Column names\n",
      "dataset 1:\n",
      "['gsv_apartments', 'gsv_commercial', 'gsv_greenery', 'gsv_historical', 'gsv_impervious', 'gsv_industrial', 'gsv_other', 'gsv_private', 'gsv_water', 'gsv_colour_hue_mean', 'gsv_colour_hue_std', 'gsv_colour_saturation_std', 'gsv_colour_brightness_mean', 'gsv_colour_brightness_std', 'gsv_disorderliness_mean', 'gsv_disorderliness_std', 'gsv_std_mean', 'gsv_std_std', 'gsv_contrast_mean', 'gsv_contrast_std', 'gsv_coherence_std']\n"
     ]
    }
   ],
   "source": [
    "pool1 = Pool(data=X, label=y)\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 1:' + str(pool1.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('dataset 1:')\n",
    "print(pool1.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "355ab999-a6db-4821-90c7-0d519ff14232",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tuned_model.eval_metrics(\n",
    "    data=pool1,\n",
    "    metrics=['TotalF1','AUC', 'Accuracy'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2ebdf6b-a7bc-4477-ba6b-2cc73124dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting metrics for plotting\n",
    "rmse_values = metrics['TotalF1']\n",
    "r2_values = metrics['Accuracy']\n",
    "trees = list(range(len(rmse_values)))  # Assuming eval_period=1 and starting from the first tree\n",
    "\n",
    "# Creating subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Plotting RMSE\n",
    "axs[0].plot(trees, rmse_values, label='TotalF1', color='tab:blue')\n",
    "axs[0].set_title('Total F1 over trees')\n",
    "axs[0].set_xlabel('Number of trees')\n",
    "axs[0].set_ylabel('Total F1')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plotting R2\n",
    "axs[1].plot(trees, r2_values, label='Accuracy', color='tab:orange')\n",
    "axs[1].set_title('Accuracy over trees')\n",
    "axs[1].set_xlabel('Number of trees')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7404081-3d8b-45d7-8bb2-e9d013a26383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gsv_contrast_mean</td>\n",
       "      <td>10.434862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gsv_colour_brightness_std</td>\n",
       "      <td>9.102764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gsv_apartments</td>\n",
       "      <td>9.094698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gsv_std_std</td>\n",
       "      <td>8.467292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gsv_colour_hue_mean</td>\n",
       "      <td>8.047206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gsv_std_mean</td>\n",
       "      <td>7.711084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gsv_coherence_std</td>\n",
       "      <td>6.749240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gsv_disorderliness_mean</td>\n",
       "      <td>5.680134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gsv_historical</td>\n",
       "      <td>5.335509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gsv_colour_brightness_mean</td>\n",
       "      <td>4.561757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gsv_colour_hue_std</td>\n",
       "      <td>4.482120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gsv_commercial</td>\n",
       "      <td>4.338009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gsv_colour_saturation_std</td>\n",
       "      <td>4.138571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gsv_contrast_std</td>\n",
       "      <td>3.950329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gsv_disorderliness_std</td>\n",
       "      <td>2.336783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gsv_private</td>\n",
       "      <td>2.241862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gsv_greenery</td>\n",
       "      <td>1.205319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gsv_water</td>\n",
       "      <td>0.658598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gsv_impervious</td>\n",
       "      <td>0.634016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gsv_industrial</td>\n",
       "      <td>0.547148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gsv_other</td>\n",
       "      <td>0.282698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature Id  Importances\n",
       "0            gsv_contrast_mean    10.434862\n",
       "1    gsv_colour_brightness_std     9.102764\n",
       "2               gsv_apartments     9.094698\n",
       "3                  gsv_std_std     8.467292\n",
       "4          gsv_colour_hue_mean     8.047206\n",
       "5                 gsv_std_mean     7.711084\n",
       "6            gsv_coherence_std     6.749240\n",
       "7      gsv_disorderliness_mean     5.680134\n",
       "8               gsv_historical     5.335509\n",
       "9   gsv_colour_brightness_mean     4.561757\n",
       "10          gsv_colour_hue_std     4.482120\n",
       "11              gsv_commercial     4.338009\n",
       "12   gsv_colour_saturation_std     4.138571\n",
       "13            gsv_contrast_std     3.950329\n",
       "14      gsv_disorderliness_std     2.336783\n",
       "15                 gsv_private     2.241862\n",
       "16                gsv_greenery     1.205319\n",
       "17                   gsv_water     0.658598\n",
       "18              gsv_impervious     0.634016\n",
       "19              gsv_industrial     0.547148\n",
       "20                   gsv_other     0.282698"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29b39dea-9e92-4016-a123-48a95ef5043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "class_names = ['00-20 low', '20-40 below average', '40-60 average', '60-80 above average', '80-100 high']\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    tuned_model,\n",
    "    X,\n",
    "    y,\n",
    "    display_labels=class_names,\n",
    "    xticks_rotation='vertical'\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd386050-1d8f-4de7-9e7c-ce346821cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 1.475548605\n",
      "bestIteration = 350\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 1.496062845\n",
      "bestIteration = 300\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 1.454625207\n",
      "bestIteration = 222\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 1.498138966\n",
      "bestIteration = 631\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 1.511530531\n",
      "bestIteration = 714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = tuned_model.get_params()\n",
    "params['loss_function'] = 'MultiClass'\n",
    "params['custom_loss'] = 'TotalF1'\n",
    "\n",
    "\n",
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y),\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=False,\n",
    "    stratified=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "042841c6-6350-4175-a735-efb8ab75cb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-MultiClass-mean</th>\n",
       "      <th>test-MultiClass-std</th>\n",
       "      <th>train-MultiClass-mean</th>\n",
       "      <th>train-MultiClass-std</th>\n",
       "      <th>test-TotalF1-mean</th>\n",
       "      <th>test-TotalF1-std</th>\n",
       "      <th>train-TotalF1-mean</th>\n",
       "      <th>train-TotalF1-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.600852</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>1.600657</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.133878</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>0.138622</td>\n",
       "      <td>0.008994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.592580</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>1.592196</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.154695</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.156242</td>\n",
       "      <td>0.004438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.585863</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>1.585264</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.151880</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.159064</td>\n",
       "      <td>0.010856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.579695</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>1.578838</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.016882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.574342</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>1.573253</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.164742</td>\n",
       "      <td>0.029075</td>\n",
       "      <td>0.171694</td>\n",
       "      <td>0.016189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1402</td>\n",
       "      <td>1.494093</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>1.372938</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.219941</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.343258</td>\n",
       "      <td>0.005651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1403</td>\n",
       "      <td>1.494099</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>1.372889</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.219894</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.343030</td>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1404</td>\n",
       "      <td>1.494108</td>\n",
       "      <td>0.020259</td>\n",
       "      <td>1.372805</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.219984</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.343324</td>\n",
       "      <td>0.005154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1405</td>\n",
       "      <td>1.494148</td>\n",
       "      <td>0.020271</td>\n",
       "      <td>1.372753</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.220010</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>0.343399</td>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1406</td>\n",
       "      <td>1.494170</td>\n",
       "      <td>0.020257</td>\n",
       "      <td>1.372713</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.220012</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.343658</td>\n",
       "      <td>0.005308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iterations  test-MultiClass-mean  test-MultiClass-std  \\\n",
       "0              0              1.600852             0.000784   \n",
       "1              1              1.592580             0.001549   \n",
       "2              2              1.585863             0.002598   \n",
       "3              3              1.579695             0.003383   \n",
       "4              4              1.574342             0.004045   \n",
       "...          ...                   ...                  ...   \n",
       "1402        1402              1.494093             0.020228   \n",
       "1403        1403              1.494099             0.020232   \n",
       "1404        1404              1.494108             0.020259   \n",
       "1405        1405              1.494148             0.020271   \n",
       "1406        1406              1.494170             0.020257   \n",
       "\n",
       "      train-MultiClass-mean  train-MultiClass-std  test-TotalF1-mean  \\\n",
       "0                  1.600657              0.000515           0.133878   \n",
       "1                  1.592196              0.000975           0.154695   \n",
       "2                  1.585264              0.001254           0.151880   \n",
       "3                  1.578838              0.001607           0.160770   \n",
       "4                  1.573253              0.001951           0.164742   \n",
       "...                     ...                   ...                ...   \n",
       "1402               1.372938              0.005228           0.219941   \n",
       "1403               1.372889              0.005235           0.219894   \n",
       "1404               1.372805              0.005260           0.219984   \n",
       "1405               1.372753              0.005282           0.220010   \n",
       "1406               1.372713              0.005268           0.220012   \n",
       "\n",
       "      test-TotalF1-std  train-TotalF1-mean  train-TotalF1-std  \n",
       "0             0.020429            0.138622           0.008994  \n",
       "1             0.019305            0.156242           0.004438  \n",
       "2             0.018658            0.159064           0.010856  \n",
       "3             0.022186            0.169544           0.016882  \n",
       "4             0.029075            0.171694           0.016189  \n",
       "...                ...                 ...                ...  \n",
       "1402          0.010099            0.343258           0.005651  \n",
       "1403          0.009972            0.343030           0.005415  \n",
       "1404          0.009832            0.343324           0.005154  \n",
       "1405          0.009792            0.343399           0.004973  \n",
       "1406          0.009797            0.343658           0.005308  \n",
       "\n",
       "[1407 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28dac7a8-ea93-46f6-973e-ad6648de5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the mean RMSE and R2 values from cv_data\n",
    "mean_multiclass = cv_data['test-MultiClass-mean']\n",
    "mean_f1 = cv_data['test-TotalF1-mean']\n",
    "iterations = range(len(mean_multiclass))\n",
    "\n",
    "# Plotting the RMSE and R2 values\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('MultiClass', color='tab:blue')\n",
    "ax1.plot(iterations, mean_multiclass, label='MultiClass', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('TotalF1', color='tab:orange')\n",
    "ax2.plot(iterations, mean_f1, label='TotalF1', color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "# Title and legend\n",
    "plt.title('CatBoost CV metrics over iterations')\n",
    "fig.tight_layout()  # To ensure the right y-label is not clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5afeaca-7090-418b-a01c-8b7213cdb88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultiClass</th>\n",
       "      <th>TotalF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.600657</td>\n",
       "      <td>0.138622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592196</td>\n",
       "      <td>0.156242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.585264</td>\n",
       "      <td>0.159064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.578838</td>\n",
       "      <td>0.169544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.573253</td>\n",
       "      <td>0.171694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1.372938</td>\n",
       "      <td>0.343258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1.372889</td>\n",
       "      <td>0.343030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1.372805</td>\n",
       "      <td>0.343324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1.372753</td>\n",
       "      <td>0.343399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1.372713</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MultiClass   TotalF1\n",
       "0       1.600657  0.138622\n",
       "1       1.592196  0.156242\n",
       "2       1.585264  0.159064\n",
       "3       1.578838  0.169544\n",
       "4       1.573253  0.171694\n",
       "...          ...       ...\n",
       "1402    1.372938  0.343258\n",
       "1403    1.372889  0.343030\n",
       "1404    1.372805  0.343324\n",
       "1405    1.372753  0.343399\n",
       "1406    1.372713  0.343658\n",
       "\n",
       "[1407 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_values = cv_data['train-MultiClass-mean']\n",
    "f1_values = cv_data['train-TotalF1-mean']\n",
    "\n",
    "# Create a DataFrame with both RMSE and R2 values\n",
    "cv_results_df = pd.DataFrame({'MultiClass': multiclass_values, 'TotalF1': f1_values})\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fab1fe5a-a3bb-451c-8b23-b564919a12be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultiClass</th>\n",
       "      <th>TotalF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.600852</td>\n",
       "      <td>0.133878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592580</td>\n",
       "      <td>0.154695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.585863</td>\n",
       "      <td>0.151880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.579695</td>\n",
       "      <td>0.160770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.574342</td>\n",
       "      <td>0.164742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1.494093</td>\n",
       "      <td>0.219941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1.494099</td>\n",
       "      <td>0.219894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1.494108</td>\n",
       "      <td>0.219984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1.494148</td>\n",
       "      <td>0.220010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1.494170</td>\n",
       "      <td>0.220012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MultiClass   TotalF1\n",
       "0       1.600852  0.133878\n",
       "1       1.592580  0.154695\n",
       "2       1.585863  0.151880\n",
       "3       1.579695  0.160770\n",
       "4       1.574342  0.164742\n",
       "...          ...       ...\n",
       "1402    1.494093  0.219941\n",
       "1403    1.494099  0.219894\n",
       "1404    1.494108  0.219984\n",
       "1405    1.494148  0.220010\n",
       "1406    1.494170  0.220012\n",
       "\n",
       "[1407 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_values = cv_data['test-MultiClass-mean']\n",
    "f1_values = cv_data['test-TotalF1-mean']\n",
    "\n",
    "# Create a DataFrame with both RMSE and R2 values\n",
    "cv_results_df = pd.DataFrame({'MultiClass': multiclass_values, 'TotalF1': f1_values})\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8213f6c6-5e94-453b-ad06-5718ce119d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4275, 5, 22)\n"
     ]
    }
   ],
   "source": [
    "shap_values = tuned_model.get_feature_importance(pool1, fstr_type='ShapValues')\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc8d32c9-3b9e-4c31-a473-544641e6b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(tuned_model)\n",
    "shap_values = explainer.shap_values(Pool(X, y))\n",
    "\n",
    "#shap.initjs()\n",
    "#shap.force_plot(explainer.expected_value[0],shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4c0d8af-f9f1-4a41-8323-d029c9a34044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The Summary Plot for the Multiclass Model\\nClass 2 - Best, Class 1 - Premium, Class 0 - Value')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, X.values, plot_type=\"bar\", class_names= class_names, feature_names = X.columns)\n",
    "plt.title('The Summary Plot for the Multiclass Model'+'\\n'+'Class 2 - Best, Class 1 - Premium, Class 0 - Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f11bc441-573c-450b-9877-2d134fd4f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '00-20 low', 1: '20-40 below average', 2: '40-60 average', 3: '60-80 above average', 4: '80-100 high'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = [\n",
    "    \"00-20 low\",\n",
    "    \"20-40 below average\",\n",
    "    \"40-60 average\",\n",
    "    \"60-80 above average\",\n",
    "    \"80-100 high\",\n",
    "]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "encoding_scheme = dict(zip(y, labels))\n",
    "print(encoding_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60e36008-3e3a-4ce8-a510-f48c8b40fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Feature importances for Amsterdam')\n",
    "shap.summary_plot(shap_values, X.values, plot_type=\"bar\", class_names= class_names, feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d84c168e-04f1-4078-b972-e064807f799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed two minor releases later.  To suppress this warning, explicitly call plt.close('all') first.\n"
     ]
    }
   ],
   "source": [
    "# Dependency plot for low-income class\n",
    "plt.switch_backend('Agg')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Impact on low income in Amsterdam')\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "shap.summary_plot(shap_values[0], X.values, feature_names=X.columns, show=False)  # Set show=False to prevent immediate display\n",
    "\n",
    "# After generating the plot, get the current figure\n",
    "fig = plt.gcf()\n",
    "\n",
    "# Save the current figure in SVG format\n",
    "fig.savefig(\"shap_dependency_plot_lowAMS_gsv.svg\", format='svg', bbox_inches='tight')\n",
    "\n",
    "# Optionally, close the figure to free up memory\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93f87994-0424-4e6d-bd3f-5b1018ec2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Impact on income below average in Amsterdam')\n",
    "shap.summary_plot(shap_values[1], X.values, feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f22ed08f-a0e2-41b3-ba4c-ba8ebd0ba316",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Impact on average income in Amsterdam')\n",
    "shap.summary_plot(shap_values[2], X.values, feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1309cd64-1e3a-41f7-a9d3-184f8ff11839",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Impact on income above average in Amsterdam')\n",
    "shap.summary_plot(shap_values[3], X.values, feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "57e88d6e-0425-4870-9581-b4e79e0768f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed two minor releases later.  To suppress this warning, explicitly call plt.close('all') first.\n"
     ]
    }
   ],
   "source": [
    "# Dependency plot for high-income class\n",
    "# Switch to 'Agg' backend, which is better suited for file outputs\n",
    "plt.switch_backend('Agg')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Impact on high income in Amsterdam')\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "shap.summary_plot(shap_values[4], X.values, feature_names=X.columns, show=False)  # Set show=False to prevent immediate display\n",
    "\n",
    "# After generating the plot, get the current figure\n",
    "fig = plt.gcf()\n",
    "\n",
    "# Save the current figure in SVG format\n",
    "fig.savefig(\"shap_dependency_plot_highAMS_gsv.svg\", format='svg', bbox_inches='tight')\n",
    "\n",
    "# Optionally, close the figure to free up memory\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d84c4-c0b3-49b0-8291-66a9b9946c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
